# -*- coding: utf-8 -*-
"""automate_Ghifari-Fikri-Yulistia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15cXFlaFWi2pvvsldyx--wW9N2W3joE1O
"""

import pandas as pd
import nltk
from nltk.corpus import stopwords
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Mengunduh stopwords dari NLTK
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def process_text_data(df):
    """
    Fungsi untuk membersihkan dan memproses teks dari DataFrame:
    - Menghapus data duplikat
    - Menyeimbangkan dataset dengan undersampling
    - Mengubah teks menjadi lowercase
    - Menghapus stopwords
    - Melakukan tokenisasi dengan Keras Tokenizer
    - Menghitung TF-IDF dari teks yang telah dibersihkan

    Parameter:
    df : pandas.DataFrame
        DataFrame yang memiliki kolom 'text' dan 'spam'

    Returns:
    x_sequences : list of list of int
        Data teks yang telah di-tokenisasi dalam bentuk sequence angka
    y : pandas.Series
        Label spam sebagai float setelah balancing
    X_tfidf : scipy.sparse.csr.csr_matrix
        Matriks TF-IDF dari teks yang telah dibersihkan
    """
    # Menghapus data duplikat
    df = df.drop_duplicates()

    # Menyeimbangkan data dengan undersampling
    n = df['spam'].value_counts().min()
    df_balanced = df.sample(frac=1).groupby('spam').head(n)

    # Memproses fitur (teks)
    x = df_balanced['text'].astype(str).str.lower()
    y = df_balanced['spam'].astype(float)

    # Menghapus stopwords
    x = x.apply(lambda text: " ".join([word for word in text.split() if word not in stop_words]))

    # Tokenisasi
    tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
    tokenizer.fit_on_texts(x)
    x_sequences = tokenizer.texts_to_sequences(x)

    # Menghitung TF-IDF
    vectorizer = TfidfVectorizer(max_features=3000)
    X_tfidf = vectorizer.fit_transform(x)

    return x_sequences, y, X_tfidf

# Contoh penggunaan
# if __name__ == "__main__":
#     df = pd.read_csv('path/to/your/input.csv')
#     x_sequences, y, X_tfidf = process_text_data(df)
#     # Lakukan sesuatu dengan x_sequences, y, dan X_tfidf